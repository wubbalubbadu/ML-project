{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "data_dir = ''\n",
    "categories = ['CDs_and_Vinyl', 'Grocery_and_Gourmet_Food', 'Toys_and_Games']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CDs_and_Vinyl/test1/product_test.json'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(data_dir, categories[0], 'test1', 'product_test.json')\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000093D54374AFE4B358EA5FBCB5776E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000B049F5B33CD310EB1AB236E20191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>000577BC760B4C7BD980939F0CB41F65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>006200BEA7FE89A51080FE699DBE479B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>04500D72BF81F8D5B00805B8E2E0E064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2A037AF5BA7F5E3CBB5527F81B2E0FBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2A049F6BDE2F1538C7AA88FF38C6C24B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2A07E088AB3E00F5C097C54326D84C37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2A0BA71EB9D661168A8CC2310FB1F82D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2A0C415B557EE513AFF70D5BFCE03F2A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59926 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  asin\n",
       "0     000093D54374AFE4B358EA5FBCB5776E\n",
       "1     0000B049F5B33CD310EB1AB236E20191\n",
       "10    000577BC760B4C7BD980939F0CB41F65\n",
       "100   006200BEA7FE89A51080FE699DBE479B\n",
       "1000  04500D72BF81F8D5B00805B8E2E0E064\n",
       "...                                ...\n",
       "9995  2A037AF5BA7F5E3CBB5527F81B2E0FBD\n",
       "9996  2A049F6BDE2F1538C7AA88FF38C6C24B\n",
       "9997  2A07E088AB3E00F5C097C54326D84C37\n",
       "9998  2A0BA71EB9D661168A8CC2310FB1F82D\n",
       "9999  2A0C415B557EE513AFF70D5BFCE03F2A\n",
       "\n",
       "[59926 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_test = pd.read_json(file_path)\n",
    "product_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E79E3AB0BA1C9B1D2EA0A5D06BEBB370</td>\n",
       "      <td>EB5EAD44ECA9E70236501677B2E1A590</td>\n",
       "      <td>1130198400</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>10 25, 2005</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>B1FEBC618A0EE0AEAC3C50FAFEB021DD</td>\n",
       "      <td>It's a pleasure to be the first to review this...</td>\n",
       "      <td>Total rip-off. Only get it if you want the Dua...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3018E371EF5B73A0F6D96B9C446F9E1A</td>\n",
       "      <td>46AF9112B390EB9782560A765122B0A2</td>\n",
       "      <td>1443225600</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>09 26, 2015</td>\n",
       "      <td>{'Format:': ' MP3 Music'}</td>\n",
       "      <td>28D37FBFE3805B4C801C08F5EC81F45F</td>\n",
       "      <td>This is not a collection of tracks for the har...</td>\n",
       "      <td>A great foray into the music of Sting and the ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>031D238E25ECCD9BD2ABEC0CCC8DEBE3</td>\n",
       "      <td>5267BAA489687DE26231DA21321345C6</td>\n",
       "      <td>1422489600</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>01 29, 2015</td>\n",
       "      <td>None</td>\n",
       "      <td>F1CD318E412B5F7226E5F377A9544FF7</td>\n",
       "      <td>one of the best albums ever made. too many gen...</td>\n",
       "      <td>defining album of the 20th century</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BC8B9DD685F363A88CBC1FDDEFC6DF41</td>\n",
       "      <td>8E94E3305440A6D4299378FF5C0D0191</td>\n",
       "      <td>1249171200</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>08 2, 2009</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>965C71418E5EE08013D24EC9BF75416D</td>\n",
       "      <td>VNV Nation continue to produce music that is t...</td>\n",
       "      <td>Worth the wait</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1CF405DBFEE0F538FA054E261EABA58B</td>\n",
       "      <td>E1EC2C26FCC3847F6F92DFA461E44629</td>\n",
       "      <td>1091318400</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>08 1, 2004</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>FBF3589622D820BD28023C7B2D7B91AC</td>\n",
       "      <td>One classic album.  probly the only classic al...</td>\n",
       "      <td>Classic rap</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256923</th>\n",
       "      <td>AFFCA77FE5D0332EC665EAFBCA940942</td>\n",
       "      <td>E2AB4D816FB759FD36D86D6200D9C27D</td>\n",
       "      <td>1418688000</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>12 16, 2014</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>91AC649EC3603DD42833BF099282AD20</td>\n",
       "      <td>Very Happy with My purchase</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256924</th>\n",
       "      <td>2C27BEDDDE8FBD7B13786BA1D18EEE4E</td>\n",
       "      <td>224F1D8BE3A18A8380979BB01CC8C7A4</td>\n",
       "      <td>1377388800</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>08 25, 2013</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>1E7F595C80EE79D6776CC844C6FE6C10</td>\n",
       "      <td>Incendio was once a big favorite of mine, I sa...</td>\n",
       "      <td>Nothing new here</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256925</th>\n",
       "      <td>68733A8B2FBAA188F37FCB66B30D055C</td>\n",
       "      <td>2FA32EC01073D1BA3FF0DCB276403225</td>\n",
       "      <td>1146528000</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>05 2, 2006</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>05293A5F2E57CF81DCF6F2CA62C829B9</td>\n",
       "      <td>Vulgar was my first Dir En Grey CD. I popped i...</td>\n",
       "      <td>\"Why can't I be pehlfect\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256926</th>\n",
       "      <td>2E7557264E2E7273C8DF1A38A50774EF</td>\n",
       "      <td>F16C874F5E64E41A02D7C0D5392FF79E</td>\n",
       "      <td>1012176000</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>01 28, 2002</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>AACDEB696DF084073B318F32C857A94B</td>\n",
       "      <td>I saw KX in concert here in Milwaukee the nigh...</td>\n",
       "      <td>Hit and miss</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256927</th>\n",
       "      <td>044C6123C40AD2A1639A8D8CB75B8A40</td>\n",
       "      <td>5F9F12B4CF6329D734954EBA98C0FF86</td>\n",
       "      <td>1096588800</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>10 1, 2004</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>1FA1FDE34A8ADC631D7B614D4417396A</td>\n",
       "      <td>Prime Cuts:  Let's Be Us Again, What I Miss th...</td>\n",
       "      <td>Lonestar Needs to be \"Us\" Again</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256928 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    asin                        reviewerID   \n",
       "0       E79E3AB0BA1C9B1D2EA0A5D06BEBB370  EB5EAD44ECA9E70236501677B2E1A590  \\\n",
       "1       3018E371EF5B73A0F6D96B9C446F9E1A  46AF9112B390EB9782560A765122B0A2   \n",
       "2       031D238E25ECCD9BD2ABEC0CCC8DEBE3  5267BAA489687DE26231DA21321345C6   \n",
       "3       BC8B9DD685F363A88CBC1FDDEFC6DF41  8E94E3305440A6D4299378FF5C0D0191   \n",
       "4       1CF405DBFEE0F538FA054E261EABA58B  E1EC2C26FCC3847F6F92DFA461E44629   \n",
       "...                                  ...                               ...   \n",
       "256923  AFFCA77FE5D0332EC665EAFBCA940942  E2AB4D816FB759FD36D86D6200D9C27D   \n",
       "256924  2C27BEDDDE8FBD7B13786BA1D18EEE4E  224F1D8BE3A18A8380979BB01CC8C7A4   \n",
       "256925  68733A8B2FBAA188F37FCB66B30D055C  2FA32EC01073D1BA3FF0DCB276403225   \n",
       "256926  2E7557264E2E7273C8DF1A38A50774EF  F16C874F5E64E41A02D7C0D5392FF79E   \n",
       "256927  044C6123C40AD2A1639A8D8CB75B8A40  5F9F12B4CF6329D734954EBA98C0FF86   \n",
       "\n",
       "        unixReviewTime  vote  verified   reviewTime   \n",
       "0           1130198400     4     False  10 25, 2005  \\\n",
       "1           1443225600     3      True  09 26, 2015   \n",
       "2           1422489600  None      True  01 29, 2015   \n",
       "3           1249171200  None      True   08 2, 2009   \n",
       "4           1091318400  None     False   08 1, 2004   \n",
       "...                ...   ...       ...          ...   \n",
       "256923      1418688000  None      True  12 16, 2014   \n",
       "256924      1377388800  None      True  08 25, 2013   \n",
       "256925      1146528000    10     False   05 2, 2006   \n",
       "256926      1012176000  None     False  01 28, 2002   \n",
       "256927      1096588800     8     False   10 1, 2004   \n",
       "\n",
       "                            style                      reviewerName   \n",
       "0        {'Format:': ' Audio CD'}  B1FEBC618A0EE0AEAC3C50FAFEB021DD  \\\n",
       "1       {'Format:': ' MP3 Music'}  28D37FBFE3805B4C801C08F5EC81F45F   \n",
       "2                            None  F1CD318E412B5F7226E5F377A9544FF7   \n",
       "3        {'Format:': ' Audio CD'}  965C71418E5EE08013D24EC9BF75416D   \n",
       "4        {'Format:': ' Audio CD'}  FBF3589622D820BD28023C7B2D7B91AC   \n",
       "...                           ...                               ...   \n",
       "256923   {'Format:': ' Audio CD'}  91AC649EC3603DD42833BF099282AD20   \n",
       "256924   {'Format:': ' Audio CD'}  1E7F595C80EE79D6776CC844C6FE6C10   \n",
       "256925   {'Format:': ' Audio CD'}  05293A5F2E57CF81DCF6F2CA62C829B9   \n",
       "256926   {'Format:': ' Audio CD'}  AACDEB696DF084073B318F32C857A94B   \n",
       "256927   {'Format:': ' Audio CD'}  1FA1FDE34A8ADC631D7B614D4417396A   \n",
       "\n",
       "                                               reviewText   \n",
       "0       It's a pleasure to be the first to review this...  \\\n",
       "1       This is not a collection of tracks for the har...   \n",
       "2       one of the best albums ever made. too many gen...   \n",
       "3       VNV Nation continue to produce music that is t...   \n",
       "4       One classic album.  probly the only classic al...   \n",
       "...                                                   ...   \n",
       "256923                        Very Happy with My purchase   \n",
       "256924  Incendio was once a big favorite of mine, I sa...   \n",
       "256925  Vulgar was my first Dir En Grey CD. I popped i...   \n",
       "256926  I saw KX in concert here in Milwaukee the nigh...   \n",
       "256927  Prime Cuts:  Let's Be Us Again, What I Miss th...   \n",
       "\n",
       "                                                  summary image  \n",
       "0       Total rip-off. Only get it if you want the Dua...  None  \n",
       "1       A great foray into the music of Sting and the ...  None  \n",
       "2                      defining album of the 20th century  None  \n",
       "3                                          Worth the wait  None  \n",
       "4                                             Classic rap  None  \n",
       "...                                                   ...   ...  \n",
       "256923                                         Five Stars  None  \n",
       "256924                                   Nothing new here  None  \n",
       "256925                          \"Why can't I be pehlfect\"  None  \n",
       "256926                                       Hit and miss  None  \n",
       "256927                    Lonestar Needs to be \"Us\" Again  None  \n",
       "\n",
       "[256928 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(data_dir, categories[0], 'test1', 'review_test.json')\n",
    "review_test = pd.read_json(file_path)\n",
    "review_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256928, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = review_test.merge(product_test, how='left', on='asin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E79E3AB0BA1C9B1D2EA0A5D06BEBB370</td>\n",
       "      <td>EB5EAD44ECA9E70236501677B2E1A590</td>\n",
       "      <td>1130198400</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>10 25, 2005</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>B1FEBC618A0EE0AEAC3C50FAFEB021DD</td>\n",
       "      <td>It's a pleasure to be the first to review this...</td>\n",
       "      <td>Total rip-off. Only get it if you want the Dua...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3018E371EF5B73A0F6D96B9C446F9E1A</td>\n",
       "      <td>46AF9112B390EB9782560A765122B0A2</td>\n",
       "      <td>1443225600</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>09 26, 2015</td>\n",
       "      <td>{'Format:': ' MP3 Music'}</td>\n",
       "      <td>28D37FBFE3805B4C801C08F5EC81F45F</td>\n",
       "      <td>This is not a collection of tracks for the har...</td>\n",
       "      <td>A great foray into the music of Sting and the ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>031D238E25ECCD9BD2ABEC0CCC8DEBE3</td>\n",
       "      <td>5267BAA489687DE26231DA21321345C6</td>\n",
       "      <td>1422489600</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>01 29, 2015</td>\n",
       "      <td>None</td>\n",
       "      <td>F1CD318E412B5F7226E5F377A9544FF7</td>\n",
       "      <td>one of the best albums ever made. too many gen...</td>\n",
       "      <td>defining album of the 20th century</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BC8B9DD685F363A88CBC1FDDEFC6DF41</td>\n",
       "      <td>8E94E3305440A6D4299378FF5C0D0191</td>\n",
       "      <td>1249171200</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>08 2, 2009</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>965C71418E5EE08013D24EC9BF75416D</td>\n",
       "      <td>VNV Nation continue to produce music that is t...</td>\n",
       "      <td>Worth the wait</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1CF405DBFEE0F538FA054E261EABA58B</td>\n",
       "      <td>E1EC2C26FCC3847F6F92DFA461E44629</td>\n",
       "      <td>1091318400</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>08 1, 2004</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>FBF3589622D820BD28023C7B2D7B91AC</td>\n",
       "      <td>One classic album.  probly the only classic al...</td>\n",
       "      <td>Classic rap</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256923</th>\n",
       "      <td>AFFCA77FE5D0332EC665EAFBCA940942</td>\n",
       "      <td>E2AB4D816FB759FD36D86D6200D9C27D</td>\n",
       "      <td>1418688000</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>12 16, 2014</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>91AC649EC3603DD42833BF099282AD20</td>\n",
       "      <td>Very Happy with My purchase</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256924</th>\n",
       "      <td>2C27BEDDDE8FBD7B13786BA1D18EEE4E</td>\n",
       "      <td>224F1D8BE3A18A8380979BB01CC8C7A4</td>\n",
       "      <td>1377388800</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>08 25, 2013</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>1E7F595C80EE79D6776CC844C6FE6C10</td>\n",
       "      <td>Incendio was once a big favorite of mine, I sa...</td>\n",
       "      <td>Nothing new here</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256925</th>\n",
       "      <td>68733A8B2FBAA188F37FCB66B30D055C</td>\n",
       "      <td>2FA32EC01073D1BA3FF0DCB276403225</td>\n",
       "      <td>1146528000</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>05 2, 2006</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>05293A5F2E57CF81DCF6F2CA62C829B9</td>\n",
       "      <td>Vulgar was my first Dir En Grey CD. I popped i...</td>\n",
       "      <td>\"Why can't I be pehlfect\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256926</th>\n",
       "      <td>2E7557264E2E7273C8DF1A38A50774EF</td>\n",
       "      <td>F16C874F5E64E41A02D7C0D5392FF79E</td>\n",
       "      <td>1012176000</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>01 28, 2002</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>AACDEB696DF084073B318F32C857A94B</td>\n",
       "      <td>I saw KX in concert here in Milwaukee the nigh...</td>\n",
       "      <td>Hit and miss</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256927</th>\n",
       "      <td>044C6123C40AD2A1639A8D8CB75B8A40</td>\n",
       "      <td>5F9F12B4CF6329D734954EBA98C0FF86</td>\n",
       "      <td>1096588800</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>10 1, 2004</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>1FA1FDE34A8ADC631D7B614D4417396A</td>\n",
       "      <td>Prime Cuts:  Let's Be Us Again, What I Miss th...</td>\n",
       "      <td>Lonestar Needs to be \"Us\" Again</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256928 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    asin                        reviewerID   \n",
       "0       E79E3AB0BA1C9B1D2EA0A5D06BEBB370  EB5EAD44ECA9E70236501677B2E1A590  \\\n",
       "1       3018E371EF5B73A0F6D96B9C446F9E1A  46AF9112B390EB9782560A765122B0A2   \n",
       "2       031D238E25ECCD9BD2ABEC0CCC8DEBE3  5267BAA489687DE26231DA21321345C6   \n",
       "3       BC8B9DD685F363A88CBC1FDDEFC6DF41  8E94E3305440A6D4299378FF5C0D0191   \n",
       "4       1CF405DBFEE0F538FA054E261EABA58B  E1EC2C26FCC3847F6F92DFA461E44629   \n",
       "...                                  ...                               ...   \n",
       "256923  AFFCA77FE5D0332EC665EAFBCA940942  E2AB4D816FB759FD36D86D6200D9C27D   \n",
       "256924  2C27BEDDDE8FBD7B13786BA1D18EEE4E  224F1D8BE3A18A8380979BB01CC8C7A4   \n",
       "256925  68733A8B2FBAA188F37FCB66B30D055C  2FA32EC01073D1BA3FF0DCB276403225   \n",
       "256926  2E7557264E2E7273C8DF1A38A50774EF  F16C874F5E64E41A02D7C0D5392FF79E   \n",
       "256927  044C6123C40AD2A1639A8D8CB75B8A40  5F9F12B4CF6329D734954EBA98C0FF86   \n",
       "\n",
       "        unixReviewTime  vote  verified   reviewTime   \n",
       "0           1130198400     4     False  10 25, 2005  \\\n",
       "1           1443225600     3      True  09 26, 2015   \n",
       "2           1422489600  None      True  01 29, 2015   \n",
       "3           1249171200  None      True   08 2, 2009   \n",
       "4           1091318400  None     False   08 1, 2004   \n",
       "...                ...   ...       ...          ...   \n",
       "256923      1418688000  None      True  12 16, 2014   \n",
       "256924      1377388800  None      True  08 25, 2013   \n",
       "256925      1146528000    10     False   05 2, 2006   \n",
       "256926      1012176000  None     False  01 28, 2002   \n",
       "256927      1096588800     8     False   10 1, 2004   \n",
       "\n",
       "                            style                      reviewerName   \n",
       "0        {'Format:': ' Audio CD'}  B1FEBC618A0EE0AEAC3C50FAFEB021DD  \\\n",
       "1       {'Format:': ' MP3 Music'}  28D37FBFE3805B4C801C08F5EC81F45F   \n",
       "2                            None  F1CD318E412B5F7226E5F377A9544FF7   \n",
       "3        {'Format:': ' Audio CD'}  965C71418E5EE08013D24EC9BF75416D   \n",
       "4        {'Format:': ' Audio CD'}  FBF3589622D820BD28023C7B2D7B91AC   \n",
       "...                           ...                               ...   \n",
       "256923   {'Format:': ' Audio CD'}  91AC649EC3603DD42833BF099282AD20   \n",
       "256924   {'Format:': ' Audio CD'}  1E7F595C80EE79D6776CC844C6FE6C10   \n",
       "256925   {'Format:': ' Audio CD'}  05293A5F2E57CF81DCF6F2CA62C829B9   \n",
       "256926   {'Format:': ' Audio CD'}  AACDEB696DF084073B318F32C857A94B   \n",
       "256927   {'Format:': ' Audio CD'}  1FA1FDE34A8ADC631D7B614D4417396A   \n",
       "\n",
       "                                               reviewText   \n",
       "0       It's a pleasure to be the first to review this...  \\\n",
       "1       This is not a collection of tracks for the har...   \n",
       "2       one of the best albums ever made. too many gen...   \n",
       "3       VNV Nation continue to produce music that is t...   \n",
       "4       One classic album.  probly the only classic al...   \n",
       "...                                                   ...   \n",
       "256923                        Very Happy with My purchase   \n",
       "256924  Incendio was once a big favorite of mine, I sa...   \n",
       "256925  Vulgar was my first Dir En Grey CD. I popped i...   \n",
       "256926  I saw KX in concert here in Milwaukee the nigh...   \n",
       "256927  Prime Cuts:  Let's Be Us Again, What I Miss th...   \n",
       "\n",
       "                                                  summary image  \n",
       "0       Total rip-off. Only get it if you want the Dua...  None  \n",
       "1       A great foray into the music of Sting and the ...  None  \n",
       "2                      defining album of the 20th century  None  \n",
       "3                                          Worth the wait  None  \n",
       "4                                             Classic rap  None  \n",
       "...                                                   ...   ...  \n",
       "256923                                         Five Stars  None  \n",
       "256924                                   Nothing new here  None  \n",
       "256925                          \"Why can't I be pehlfect\"  None  \n",
       "256926                                       Hit and miss  None  \n",
       "256927                    Lonestar Needs to be \"Us\" Again  None  \n",
       "\n",
       "[256928 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some reviewText are missing, convert them to empty string\n",
    "\n",
    "test1['reviewText'] = test1['reviewText'].fillna('')\n",
    "test1['summary'] = test1['summary'].fillna('')\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove stop words\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# # download the stopwords corpus if necessary\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# # load the stopwords\n",
    "# stop_words = stopwords.words('english')\n",
    "\n",
    "# # remove the stop words from the reviewText column\n",
    "# from tqdm import tqdm\n",
    "# tqdm.pandas()\n",
    "# c0_train['reviewText'] = c0_train['reviewText'].progress_apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import logging\n",
    "# import nltk\n",
    "# from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # load the data\n",
    "# data = test1\n",
    "\n",
    "# # group the data by asin\n",
    "# grouped_data = data.groupby(\"asin\")\n",
    "\n",
    "# # initialize the sentiment analyzer\n",
    "# sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# # compute the sentiment scores for each product\n",
    "# product_sentiments = []\n",
    "# for asin, reviews in tqdm(grouped_data):\n",
    "#     try:\n",
    "#         sentiment_scores = []\n",
    "#         for review in reviews[\"reviewText\"]:\n",
    "#             score = sia.polarity_scores(review)[\"compound\"]\n",
    "#             sentiment_scores.append(score)\n",
    "#             logging.info(f'Successfully computed sentiment score for review: {review[:50]}')\n",
    "#         avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if len(sentiment_scores) > 0 else 0\n",
    "#         product_sentiments.append({\"asin\": asin, \"sentiment\": avg_sentiment})\n",
    "#     except Exception as e:\n",
    "#         logging.error(f'Error computing sentiment score for asin {asin}. Error message: {str(e)}')\n",
    "\n",
    "# # create a new dataframe for the sentiment scores\n",
    "# test_sentiment_df = pd.DataFrame(product_sentiments)\n",
    "\n",
    "# # save the dataframe to a CSV file\n",
    "# test_sentiment_df.to_csv(\"test_1_product_sentiment.csv\", index=False)\n",
    "\n",
    "# # log the successful completion of the program\n",
    "# logging.info(\"Sentiment analysis completed successfully.\")\n",
    "\n",
    "# test_sentiment_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>image</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E79E3AB0BA1C9B1D2EA0A5D06BEBB370</td>\n",
       "      <td>EB5EAD44ECA9E70236501677B2E1A590</td>\n",
       "      <td>1130198400</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>10 25, 2005</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>B1FEBC618A0EE0AEAC3C50FAFEB021DD</td>\n",
       "      <td>It's a pleasure to be the first to review this...</td>\n",
       "      <td>Total rip-off. Only get it if you want the Dua...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.867580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3018E371EF5B73A0F6D96B9C446F9E1A</td>\n",
       "      <td>46AF9112B390EB9782560A765122B0A2</td>\n",
       "      <td>1443225600</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>09 26, 2015</td>\n",
       "      <td>{'Format:': ' MP3 Music'}</td>\n",
       "      <td>28D37FBFE3805B4C801C08F5EC81F45F</td>\n",
       "      <td>This is not a collection of tracks for the har...</td>\n",
       "      <td>A great foray into the music of Sting and the ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.744059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>031D238E25ECCD9BD2ABEC0CCC8DEBE3</td>\n",
       "      <td>5267BAA489687DE26231DA21321345C6</td>\n",
       "      <td>1422489600</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>01 29, 2015</td>\n",
       "      <td>None</td>\n",
       "      <td>F1CD318E412B5F7226E5F377A9544FF7</td>\n",
       "      <td>one of the best albums ever made. too many gen...</td>\n",
       "      <td>defining album of the 20th century</td>\n",
       "      <td>None</td>\n",
       "      <td>0.817088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BC8B9DD685F363A88CBC1FDDEFC6DF41</td>\n",
       "      <td>8E94E3305440A6D4299378FF5C0D0191</td>\n",
       "      <td>1249171200</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>08 2, 2009</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>965C71418E5EE08013D24EC9BF75416D</td>\n",
       "      <td>VNV Nation continue to produce music that is t...</td>\n",
       "      <td>Worth the wait</td>\n",
       "      <td>None</td>\n",
       "      <td>0.962250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1CF405DBFEE0F538FA054E261EABA58B</td>\n",
       "      <td>E1EC2C26FCC3847F6F92DFA461E44629</td>\n",
       "      <td>1091318400</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>08 1, 2004</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>FBF3589622D820BD28023C7B2D7B91AC</td>\n",
       "      <td>One classic album.  probly the only classic al...</td>\n",
       "      <td>Classic rap</td>\n",
       "      <td>None</td>\n",
       "      <td>0.656300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256923</th>\n",
       "      <td>AFFCA77FE5D0332EC665EAFBCA940942</td>\n",
       "      <td>E2AB4D816FB759FD36D86D6200D9C27D</td>\n",
       "      <td>1418688000</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>12 16, 2014</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>91AC649EC3603DD42833BF099282AD20</td>\n",
       "      <td>Very Happy with My purchase</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>None</td>\n",
       "      <td>0.736700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256924</th>\n",
       "      <td>2C27BEDDDE8FBD7B13786BA1D18EEE4E</td>\n",
       "      <td>224F1D8BE3A18A8380979BB01CC8C7A4</td>\n",
       "      <td>1377388800</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>08 25, 2013</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>1E7F595C80EE79D6776CC844C6FE6C10</td>\n",
       "      <td>Incendio was once a big favorite of mine, I sa...</td>\n",
       "      <td>Nothing new here</td>\n",
       "      <td>None</td>\n",
       "      <td>0.358750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256925</th>\n",
       "      <td>68733A8B2FBAA188F37FCB66B30D055C</td>\n",
       "      <td>2FA32EC01073D1BA3FF0DCB276403225</td>\n",
       "      <td>1146528000</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>05 2, 2006</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>05293A5F2E57CF81DCF6F2CA62C829B9</td>\n",
       "      <td>Vulgar was my first Dir En Grey CD. I popped i...</td>\n",
       "      <td>\"Why can't I be pehlfect\"</td>\n",
       "      <td>None</td>\n",
       "      <td>0.131250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256926</th>\n",
       "      <td>2E7557264E2E7273C8DF1A38A50774EF</td>\n",
       "      <td>F16C874F5E64E41A02D7C0D5392FF79E</td>\n",
       "      <td>1012176000</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>01 28, 2002</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>AACDEB696DF084073B318F32C857A94B</td>\n",
       "      <td>I saw KX in concert here in Milwaukee the nigh...</td>\n",
       "      <td>Hit and miss</td>\n",
       "      <td>None</td>\n",
       "      <td>0.814175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256927</th>\n",
       "      <td>044C6123C40AD2A1639A8D8CB75B8A40</td>\n",
       "      <td>5F9F12B4CF6329D734954EBA98C0FF86</td>\n",
       "      <td>1096588800</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>10 1, 2004</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>1FA1FDE34A8ADC631D7B614D4417396A</td>\n",
       "      <td>Prime Cuts:  Let's Be Us Again, What I Miss th...</td>\n",
       "      <td>Lonestar Needs to be \"Us\" Again</td>\n",
       "      <td>None</td>\n",
       "      <td>0.982700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256928 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    asin                        reviewerID   \n",
       "0       E79E3AB0BA1C9B1D2EA0A5D06BEBB370  EB5EAD44ECA9E70236501677B2E1A590  \\\n",
       "1       3018E371EF5B73A0F6D96B9C446F9E1A  46AF9112B390EB9782560A765122B0A2   \n",
       "2       031D238E25ECCD9BD2ABEC0CCC8DEBE3  5267BAA489687DE26231DA21321345C6   \n",
       "3       BC8B9DD685F363A88CBC1FDDEFC6DF41  8E94E3305440A6D4299378FF5C0D0191   \n",
       "4       1CF405DBFEE0F538FA054E261EABA58B  E1EC2C26FCC3847F6F92DFA461E44629   \n",
       "...                                  ...                               ...   \n",
       "256923  AFFCA77FE5D0332EC665EAFBCA940942  E2AB4D816FB759FD36D86D6200D9C27D   \n",
       "256924  2C27BEDDDE8FBD7B13786BA1D18EEE4E  224F1D8BE3A18A8380979BB01CC8C7A4   \n",
       "256925  68733A8B2FBAA188F37FCB66B30D055C  2FA32EC01073D1BA3FF0DCB276403225   \n",
       "256926  2E7557264E2E7273C8DF1A38A50774EF  F16C874F5E64E41A02D7C0D5392FF79E   \n",
       "256927  044C6123C40AD2A1639A8D8CB75B8A40  5F9F12B4CF6329D734954EBA98C0FF86   \n",
       "\n",
       "        unixReviewTime  vote  verified   reviewTime   \n",
       "0           1130198400     4     False  10 25, 2005  \\\n",
       "1           1443225600     3      True  09 26, 2015   \n",
       "2           1422489600  None      True  01 29, 2015   \n",
       "3           1249171200  None      True   08 2, 2009   \n",
       "4           1091318400  None     False   08 1, 2004   \n",
       "...                ...   ...       ...          ...   \n",
       "256923      1418688000  None      True  12 16, 2014   \n",
       "256924      1377388800  None      True  08 25, 2013   \n",
       "256925      1146528000    10     False   05 2, 2006   \n",
       "256926      1012176000  None     False  01 28, 2002   \n",
       "256927      1096588800     8     False   10 1, 2004   \n",
       "\n",
       "                            style                      reviewerName   \n",
       "0        {'Format:': ' Audio CD'}  B1FEBC618A0EE0AEAC3C50FAFEB021DD  \\\n",
       "1       {'Format:': ' MP3 Music'}  28D37FBFE3805B4C801C08F5EC81F45F   \n",
       "2                            None  F1CD318E412B5F7226E5F377A9544FF7   \n",
       "3        {'Format:': ' Audio CD'}  965C71418E5EE08013D24EC9BF75416D   \n",
       "4        {'Format:': ' Audio CD'}  FBF3589622D820BD28023C7B2D7B91AC   \n",
       "...                           ...                               ...   \n",
       "256923   {'Format:': ' Audio CD'}  91AC649EC3603DD42833BF099282AD20   \n",
       "256924   {'Format:': ' Audio CD'}  1E7F595C80EE79D6776CC844C6FE6C10   \n",
       "256925   {'Format:': ' Audio CD'}  05293A5F2E57CF81DCF6F2CA62C829B9   \n",
       "256926   {'Format:': ' Audio CD'}  AACDEB696DF084073B318F32C857A94B   \n",
       "256927   {'Format:': ' Audio CD'}  1FA1FDE34A8ADC631D7B614D4417396A   \n",
       "\n",
       "                                               reviewText   \n",
       "0       It's a pleasure to be the first to review this...  \\\n",
       "1       This is not a collection of tracks for the har...   \n",
       "2       one of the best albums ever made. too many gen...   \n",
       "3       VNV Nation continue to produce music that is t...   \n",
       "4       One classic album.  probly the only classic al...   \n",
       "...                                                   ...   \n",
       "256923                        Very Happy with My purchase   \n",
       "256924  Incendio was once a big favorite of mine, I sa...   \n",
       "256925  Vulgar was my first Dir En Grey CD. I popped i...   \n",
       "256926  I saw KX in concert here in Milwaukee the nigh...   \n",
       "256927  Prime Cuts:  Let's Be Us Again, What I Miss th...   \n",
       "\n",
       "                                                  summary image  sentiment  \n",
       "0       Total rip-off. Only get it if you want the Dua...  None   0.867580  \n",
       "1       A great foray into the music of Sting and the ...  None   0.744059  \n",
       "2                      defining album of the 20th century  None   0.817088  \n",
       "3                                          Worth the wait  None   0.962250  \n",
       "4                                             Classic rap  None   0.656300  \n",
       "...                                                   ...   ...        ...  \n",
       "256923                                         Five Stars  None   0.736700  \n",
       "256924                                   Nothing new here  None   0.358750  \n",
       "256925                          \"Why can't I be pehlfect\"  None   0.131250  \n",
       "256926                                       Hit and miss  None   0.814175  \n",
       "256927                    Lonestar Needs to be \"Us\" Again  None   0.982700  \n",
       "\n",
       "[256928 rows x 12 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the sentiment_df with c0_train\n",
    "\n",
    "# read product_sentiment.csv as a dataframe\n",
    "sentiment_df = pd.read_csv(\"test_1_product_sentiment.csv\")\n",
    "\n",
    "# merge the sentiment_df with c0_train\n",
    "merged_df = pd.merge(test1, sentiment_df, on=\"asin\", how=\"left\")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'{\\'Format:\\': \\' 5.25\" disk\\'}',\n",
       " \"{'Format:': ' Album'}\",\n",
       " \"{'Format:': ' Amazon Video'}\",\n",
       " \"{'Format:': ' Audio CD'}\",\n",
       " \"{'Format:': ' Audio Cassette'}\",\n",
       " \"{'Format:': ' Audio-Video'}\",\n",
       " \"{'Format:': ' Blu-ray Audio'}\",\n",
       " \"{'Format:': ' Blu-ray'}\",\n",
       " \"{'Format:': ' CD-R'}\",\n",
       " \"{'Format:': ' DVD Audio'}\",\n",
       " \"{'Format:': ' DVD'}\",\n",
       " \"{'Format:': ' HD DVD'}\",\n",
       " \"{'Format:': ' Hardcover'}\",\n",
       " \"{'Format:': ' Interactive DVD'}\",\n",
       " \"{'Format:': ' MP3 Music'}\",\n",
       " \"{'Format:': ' MiniDisc'}\",\n",
       " \"{'Format:': ' Misc.'}\",\n",
       " \"{'Format:': ' Paperback'}\",\n",
       " \"{'Format:': ' Sheet music'}\",\n",
       " \"{'Format:': ' USB Memory Stick'}\",\n",
       " \"{'Format:': ' Unknown Binding'}\",\n",
       " \"{'Format:': ' VHS Tape'}\",\n",
       " \"{'Format:': ' Vinyl Bound'}\",\n",
       " \"{'Format:': ' Vinyl'}\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the unique values in merged_df[\"style\"]\n",
    "values = []\n",
    "for value in merged_df[\"style\"]:\n",
    "    # if value isn't None, add its whole representation to values list\n",
    "    if value is not None:\n",
    "        values.append(str(value))\n",
    "unique_values = set(values)\n",
    "unique_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>style</th>\n",
       "      <th>image</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>reviewerID_encoded</th>\n",
       "      <th>asin_encoded</th>\n",
       "      <th>reviewerName_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E79E3AB0BA1C9B1D2EA0A5D06BEBB370</td>\n",
       "      <td>1.130198e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.867580</td>\n",
       "      <td>79926.0</td>\n",
       "      <td>54214.0</td>\n",
       "      <td>51722.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3018E371EF5B73A0F6D96B9C446F9E1A</td>\n",
       "      <td>1.443226e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>14.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.744059</td>\n",
       "      <td>24168.0</td>\n",
       "      <td>11384.0</td>\n",
       "      <td>11812.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>031D238E25ECCD9BD2ABEC0CCC8DEBE3</td>\n",
       "      <td>1.422490e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.817088</td>\n",
       "      <td>28042.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>70295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BC8B9DD685F363A88CBC1FDDEFC6DF41</td>\n",
       "      <td>1.249171e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.962250</td>\n",
       "      <td>48270.0</td>\n",
       "      <td>44176.0</td>\n",
       "      <td>43736.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1CF405DBFEE0F538FA054E261EABA58B</td>\n",
       "      <td>1.091318e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.656300</td>\n",
       "      <td>76689.0</td>\n",
       "      <td>6899.0</td>\n",
       "      <td>73254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256923</th>\n",
       "      <td>AFFCA77FE5D0332EC665EAFBCA940942</td>\n",
       "      <td>1.418688e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.736700</td>\n",
       "      <td>76931.0</td>\n",
       "      <td>41238.0</td>\n",
       "      <td>42371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256924</th>\n",
       "      <td>2C27BEDDDE8FBD7B13786BA1D18EEE4E</td>\n",
       "      <td>1.377389e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.358750</td>\n",
       "      <td>11856.0</td>\n",
       "      <td>10493.0</td>\n",
       "      <td>8769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256925</th>\n",
       "      <td>68733A8B2FBAA188F37FCB66B30D055C</td>\n",
       "      <td>1.146528e+09</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>16378.0</td>\n",
       "      <td>24581.0</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256926</th>\n",
       "      <td>2E7557264E2E7273C8DF1A38A50774EF</td>\n",
       "      <td>1.012176e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.814175</td>\n",
       "      <td>81949.0</td>\n",
       "      <td>11028.0</td>\n",
       "      <td>49624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256927</th>\n",
       "      <td>044C6123C40AD2A1639A8D8CB75B8A40</td>\n",
       "      <td>1.096589e+09</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.982700</td>\n",
       "      <td>32630.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>9138.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256928 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    asin  unixReviewTime  vote  verified   \n",
       "0       E79E3AB0BA1C9B1D2EA0A5D06BEBB370    1.130198e+09     4     False  \\\n",
       "1       3018E371EF5B73A0F6D96B9C446F9E1A    1.443226e+09     3      True   \n",
       "2       031D238E25ECCD9BD2ABEC0CCC8DEBE3    1.422490e+09  None      True   \n",
       "3       BC8B9DD685F363A88CBC1FDDEFC6DF41    1.249171e+09  None      True   \n",
       "4       1CF405DBFEE0F538FA054E261EABA58B    1.091318e+09  None     False   \n",
       "...                                  ...             ...   ...       ...   \n",
       "256923  AFFCA77FE5D0332EC665EAFBCA940942    1.418688e+09  None      True   \n",
       "256924  2C27BEDDDE8FBD7B13786BA1D18EEE4E    1.377389e+09  None      True   \n",
       "256925  68733A8B2FBAA188F37FCB66B30D055C    1.146528e+09    10     False   \n",
       "256926  2E7557264E2E7273C8DF1A38A50774EF    1.012176e+09  None     False   \n",
       "256927  044C6123C40AD2A1639A8D8CB75B8A40    1.096589e+09     8     False   \n",
       "\n",
       "        style image  sentiment  reviewerID_encoded  asin_encoded   \n",
       "0         3.0  None   0.867580             79926.0       54214.0  \\\n",
       "1        14.0  None   0.744059             24168.0       11384.0   \n",
       "2        17.0  None   0.817088             28042.0         704.0   \n",
       "3         3.0  None   0.962250             48270.0       44176.0   \n",
       "4         3.0  None   0.656300             76689.0        6899.0   \n",
       "...       ...   ...        ...                 ...           ...   \n",
       "256923    3.0  None   0.736700             76931.0       41238.0   \n",
       "256924    3.0  None   0.358750             11856.0       10493.0   \n",
       "256925    3.0  None   0.131250             16378.0       24581.0   \n",
       "256926    3.0  None   0.814175             81949.0       11028.0   \n",
       "256927    3.0  None   0.982700             32630.0         995.0   \n",
       "\n",
       "        reviewerName_encoded  \n",
       "0                    51722.0  \n",
       "1                    11812.0  \n",
       "2                    70295.0  \n",
       "3                    43736.0  \n",
       "4                    73254.0  \n",
       "...                      ...  \n",
       "256923               42371.0  \n",
       "256924                8769.0  \n",
       "256925                1440.0  \n",
       "256926               49624.0  \n",
       "256927                9138.0  \n",
       "\n",
       "[256928 rows x 10 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "# Define a function to extract the format information from the \"style\" column\n",
    "def extract_format(style):\n",
    "    if isinstance(style, int):\n",
    "        return float(style)\n",
    "    if style is None:\n",
    "        return \"None\"\n",
    "    else:\n",
    "        return style.get(\"Format:\", \"None\").strip()\n",
    "\n",
    "# Apply the function to the \"style\" column to extract the format information\n",
    "merged_df[\"style\"] = merged_df[\"style\"].apply(extract_format)\n",
    "\n",
    "# Encode the columns\n",
    "encoder = LabelEncoder()\n",
    "merged_df[\"style\"] = encoder.fit_transform(merged_df[\"style\"])\n",
    "merged_df[\"reviewerID_encoded\"] = encoder.fit_transform(merged_df[\"reviewerID\"])\n",
    "merged_df[\"asin_encoded\"] = encoder.fit_transform(merged_df[\"asin\"])\n",
    "merged_df[\"reviewerName_encoded\"] = encoder.fit_transform(merged_df[\"reviewerName\"])\n",
    "\n",
    "# # Create a numImages column\n",
    "# merged_df[\"image\"] = merged_df[\"image\"].apply(lambda x: len(x) if x is not None else 0)\n",
    "\n",
    "# # Create a vote column\n",
    "# merged_df[\"vote\"] = merged_df[\"vote\"].apply(lambda x: float(x.replace(\",\", \"\")) if x is not None else 0)\n",
    "\n",
    "# # Create a verified column that is 1 if the review is verified, 0 otherwise\n",
    "# merged_df[\"verified\"] = merged_df[\"verified\"].astype(int)\n",
    "\n",
    "# drop reviewText, reviewTime, reviewerID, summary \n",
    "# merged_df = merged_df.drop(columns=[\"reviewText\", \"reviewTime\", \"reviewerID\", \"summary\", \"reviewerName\"])\n",
    "# merged_df[['unixReviewTime', 'vote', 'verified', 'style', 'image', 'sentiment', 'reviewerID_encoded', 'asin_encoded', 'reviewerName_encoded']] = merged_df[['unixReviewTime', 'vote', 'verified', 'style', 'image','sentiment', 'reviewerID_encoded', 'asin_encoded', 'reviewerName_encoded']].astype(float)\n",
    "merged_df = merged_df.drop(columns=[\"reviewText\", \"reviewTime\", \"reviewerID\", \"summary\", \"reviewerName\"])\n",
    "merged_df[['unixReviewTime', 'style', 'sentiment', 'reviewerID_encoded', 'asin_encoded', 'reviewerName_encoded']] = merged_df[['unixReviewTime', 'style', 'sentiment', 'reviewerID_encoded', 'asin_encoded', 'reviewerName_encoded']].astype(float)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.stats as stats\n",
    "\n",
    "# # drop the 'asin' column\n",
    "# merged_df_without_asin = merged_df.drop('asin', axis=1)\n",
    "\n",
    "# # calculate the correlation between all features (excluding 'asin') and awesomeness\n",
    "# corr_df = merged_df_without_asin.corr()['awesomeness'].to_frame()\n",
    "# corr_df['p_value'] = [stats.pearsonr(merged_df_without_asin[col], merged_df_without_asin['awesomeness'])[1] for col in merged_df_without_asin.columns]\n",
    "\n",
    "# # sort the dataframe by the absolute value of correlation\n",
    "# corr_df['abs_corr'] = corr_df['awesomeness'].abs()\n",
    "# corr_df.sort_values('abs_corr', ascending=False, inplace=True)\n",
    "\n",
    "# # print the top 10 features and their p-values\n",
    "# print(corr_df.head(10)[['awesomeness', 'p_value']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import logging\n",
    "\n",
    "# # group the data by asin\n",
    "# grouped_data = c0_train.groupby(\"asin\")\n",
    "\n",
    "# # calculate the required metrics for each product\n",
    "# product_metrics = []\n",
    "# for asin, reviews in tqdm(grouped_data):\n",
    "#     try:\n",
    "#         num_reviews = len(reviews)\n",
    "#         num_verified_reviews = len(reviews[reviews[\"verified\"] == True])\n",
    "#         num_images_on_reviews = reviews[\"image\"].apply(lambda x: len(x) if x is not None else 0).sum() \n",
    "#         mean_helpful_votes = reviews[\"vote\"].apply(lambda x: float(x.replace(\",\", \"\")) if x is not None else 0).mean()\n",
    "#         mean_review_length = reviews[\"reviewText\"].apply(lambda x: len(x.split())).mean()\n",
    "#         percentage_verified_purchases = num_verified_reviews / num_reviews * 100\n",
    "        \n",
    "#         product_metrics.append({\n",
    "#             \"asin\": str(asin), \n",
    "#             \"mean_helpful_votes\": mean_helpful_votes,\n",
    "#             \"mean_review_length\": mean_review_length,\n",
    "#             \"percentage_verified_purchases\": percentage_verified_purchases,\n",
    "#             \"num_images_on_reviews\": num_images_on_reviews\n",
    "#         })\n",
    "#     except Exception as e:\n",
    "#         logging.error(f'Error computing metrics for asin {asin}. Error message: {str(e)}')\n",
    "\n",
    "# # create a new dataframe for the metrics\n",
    "# metrics_df = pd.DataFrame(product_metrics)\n",
    "\n",
    "# # save the dataframe to a CSV file\n",
    "# metrics_df.to_csv(\"product_metrics.csv\", index=False)\n",
    "\n",
    "# # log the successful completion of the program\n",
    "# logging.info(\"Metrics calculation completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import logging\n",
    "\n",
    "# # group the data by asin and verified\n",
    "# grouped_data = c0_train.groupby([\"asin\", \"verified\"])\n",
    "\n",
    "# # calculate the required metrics for each product\n",
    "# product_metrics = []\n",
    "# for (asin, verified), reviews in tqdm(grouped_data):\n",
    "#     try:\n",
    "#         mean_helpful_votes = reviews.loc[reviews[\"vote\"].notnull(), \"vote\"].apply(lambda x: (float(x.replace(\",\", \"\"))/1)+1).mean()\n",
    "        \n",
    "#         product_metrics.append({\n",
    "#             \"asin\": str(asin), \n",
    "#             \"verified\": verified,\n",
    "#             \"mean_helpful_votes\": mean_helpful_votes\n",
    "#         })\n",
    "#     except Exception as e:\n",
    "#         logging.error(f'Error computing metrics for asin {asin}. Error message: {str(e)}')\n",
    "\n",
    "# # create a new dataframe for the metrics\n",
    "# metrics_df = pd.DataFrame(product_metrics)\n",
    "\n",
    "# # save the dataframe to a CSV file\n",
    "# metrics_df.to_csv(\"mean_helpful_votes.csv\", index=False)\n",
    "\n",
    "# # log the successful completion of the program\n",
    "# logging.info(\"Metrics calculation completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_df = pd.read_csv(\"product_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpful_votes_df = pd.read_csv(\"mean_helpful_votes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.merge(sentiment_df, helpful_votes_df, on=\"asin\", how=\"left\")\n",
    "# df = df.merge(c0_product_train, how='left', on='asin')\n",
    "# df['weighted_sentiment'] = df['sentiment'] * df['mean_helpful_votes']\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import logging\n",
    "# import pandas as pd\n",
    "# from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# # initialize the sentiment analyzer\n",
    "# sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# # create two separate dataframes for verified and unverified reviews\n",
    "# verified_reviews = c0_train[c0_train[\"verified\"] == True]\n",
    "# unverified_reviews = c0_train[c0_train[\"verified\"] == False]\n",
    "\n",
    "# # calculate the sentiment scores for each product in verified and unverified reviews\n",
    "# verified_sentiments = []\n",
    "# unverified_sentiments = []\n",
    "\n",
    "# for asin, reviews in tqdm(verified_reviews.groupby(\"asin\")):\n",
    "#     try:\n",
    "#         sentiment_scores = []\n",
    "#         for review in reviews[\"reviewText\"]:\n",
    "#             score = sia.polarity_scores(review)[\"compound\"]\n",
    "#             sentiment_scores.append(score)\n",
    "#         avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if len(sentiment_scores) > 0 else 0\n",
    "#         verified_sentiments.append({\"asin\": asin, \"sentiment\": avg_sentiment})\n",
    "#     except Exception as e:\n",
    "#         logging.error(f'Error computing sentiment score for asin {asin}. Error message: {str(e)}')\n",
    "\n",
    "# for asin, reviews in tqdm(unverified_reviews.groupby(\"asin\")):\n",
    "#     try:\n",
    "#         sentiment_scores = []\n",
    "#         for review in reviews[\"reviewText\"]:\n",
    "#             score = sia.polarity_scores(review)[\"compound\"]\n",
    "#             sentiment_scores.append(score)\n",
    "#         avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if len(sentiment_scores) > 0 else 0\n",
    "#         unverified_sentiments.append({\"asin\": asin, \"sentiment\": avg_sentiment})\n",
    "#     except Exception as e:\n",
    "#         logging.error(f'Error computing sentiment score for asin {asin}. Error message: {str(e)}')\n",
    "\n",
    "# # create dataframes for the sentiment scores\n",
    "# verified_sentiment_df = pd.DataFrame(verified_sentiments)\n",
    "# unverified_sentiment_df = pd.DataFrame(unverified_sentiments)\n",
    "\n",
    "# # group the data by asin and verified for helpful votes\n",
    "# grouped_data = c0_train.groupby([\"asin\", \"verified\"])\n",
    "\n",
    "# # calculate the required metrics for each product and verified status\n",
    "# product_metrics = []\n",
    "# for (asin, verified), reviews in tqdm(grouped_data):\n",
    "#     try:\n",
    "#         mean_helpful_votes = reviews.loc[reviews[\"vote\"].notnull(), \"vote\"].apply(lambda x: (float(x.replace(\",\", \"\"))/1)+1).mean()\n",
    "        \n",
    "#         product_metrics.append({\n",
    "#             \"asin\": str(asin), \n",
    "#             \"verified\": verified,\n",
    "#             \"mean_helpful_votes\": mean_helpful_votes\n",
    "#         })\n",
    "#     except Exception as e:\n",
    "#         logging.error(f'Error computing metrics for asin {asin}. Error message: {str(e)}')\n",
    "\n",
    "# # create a new dataframe for the metrics\n",
    "# metrics_df = pd.DataFrame(product_metrics)\n",
    "\n",
    "# # save the dataframe to a CSV file\n",
    "# metrics_df.to_csv(\"mean_helpful_votes.csv\", index=False)\n",
    "\n",
    "# # log the successful completion of the program\n",
    "# logging.info(\"Metrics calculation completed successfully.\")\n",
    "\n",
    "# # read in the mean helpful votes dataframe\n",
    "# mean_helpful_votes_df = pd.read_csv(\"mean_helpful_votes.csv\")\n",
    "\n",
    "# # merge the sentiment and mean helpful votes dataframes\n",
    "# verified_df = pd.merge(verified_sentiment_df, mean_helpful_votes_df[mean_helpful_votes_df[\"verified\"] == True], on=\"asin\", how=\"left\")\n",
    "# unverified_df = pd.merge(unverified_sentiment_df, mean_helpful_votes_df[mean_helpful_votes_df[\"verified\"] == False], on=\"asin\", how=\"left\")\n",
    "\n",
    "# # calculate the weighted sentiment for verified and unverified reviews separately\n",
    "# verified_df['weighted_sentiment'] = verified_df['sentiment'] * verified_df['mean_helpful_votes']\n",
    "# unverified_df['weighted_sentiment'] = unverified_df['sentiment'] * unverified_df['mean_helpful_votes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into features and target\n",
    "# experimented with just having sentiment as feature vector\n",
    "df = merged_df\n",
    "X_test = df.drop(columns=[\"asin\", \"image\", \"reviewerID_encoded\", \"reviewerName_encoded\", \"asin_encoded\", \"vote\"])\n",
    "X_test.to_csv(\"test1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>verified</th>\n",
       "      <th>style</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.130198e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.867580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.443226e+09</td>\n",
       "      <td>True</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.744059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.422490e+09</td>\n",
       "      <td>True</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.817088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.249171e+09</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.962250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.091318e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.656300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256923</th>\n",
       "      <td>1.418688e+09</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.736700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256924</th>\n",
       "      <td>1.377389e+09</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.358750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256925</th>\n",
       "      <td>1.146528e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.131250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256926</th>\n",
       "      <td>1.012176e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.814175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256927</th>\n",
       "      <td>1.096589e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.982700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256928 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        unixReviewTime  verified  style  sentiment\n",
       "0         1.130198e+09     False    3.0   0.867580\n",
       "1         1.443226e+09      True   14.0   0.744059\n",
       "2         1.422490e+09      True   17.0   0.817088\n",
       "3         1.249171e+09      True    3.0   0.962250\n",
       "4         1.091318e+09     False    3.0   0.656300\n",
       "...                ...       ...    ...        ...\n",
       "256923    1.418688e+09      True    3.0   0.736700\n",
       "256924    1.377389e+09      True    3.0   0.358750\n",
       "256925    1.146528e+09     False    3.0   0.131250\n",
       "256926    1.012176e+09     False    3.0   0.814175\n",
       "256927    1.096589e+09     False    3.0   0.982700\n",
       "\n",
       "[256928 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import precision_score\n",
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define hyperparameters for each classifier\n",
    "# gnb_params = {}\n",
    "# knn_params = {'n_neighbors': [3, 5, 7, 9]}\n",
    "# dtc_params = {'criterion': ['gini', 'entropy'], 'max_depth': [5, 10, 15, None], 'min_samples_split': [2, 5, 10]}\n",
    "# # svc_params = {'kernel': ['linear'], 'C': [0.1, 1, 10], 'gamma': ['scale']}\n",
    "# lr_params = {'penalty': ['l2'], 'C': [0.1, 1, 10]}\n",
    "# rfc_params = {'n_estimators': [50, 100], 'criterion': ['gini', 'entropy'], 'max_depth': [5, 10, None]}\n",
    "\n",
    "# # fit classifiers and make predictions on test set\n",
    "# best_f1_score = 0\n",
    "# best_classifier = None\n",
    "# classifiers = [GaussianNB(), KNeighborsClassifier(), DecisionTreeClassifier(), LogisticRegression(), RandomForestClassifier()]\n",
    "# classifier_params = [gnb_params, knn_params, dtc_params, lr_params, rfc_params]\n",
    "# classifier_names = [\"Naive Bayes\", \"K-NN\", \"Decision Trees\", \"Logistic Regression\", \"Random Forest\"]\n",
    "\n",
    "# for classifier, params, name in zip(classifiers, classifier_params, classifier_names):\n",
    "#     clf = GridSearchCV(classifier, params, scoring='f1', cv=5)\n",
    "#     with tqdm(total=100, desc=name) as pbar:\n",
    "#         clf.fit(X_train, y_train)\n",
    "#         y_pred = clf.predict(X_test)\n",
    "\n",
    "#     # compute evaluation metrics\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     precision = precision_score(y_test, y_pred)\n",
    "#     recall = recall_score(y_test, y_pred)\n",
    "#     f1 = f1_score(y_test, y_pred)\n",
    "#     cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#     # print results\n",
    "#     print(f\"Results for {name}:\")\n",
    "#     print(f\"Best parameters: {clf.best_params_}\")\n",
    "#     print(f\"Accuracy: {accuracy}\")\n",
    "#     print(f\"Precision: {precision}\")\n",
    "#     print(f\"Recall: {recall}\")\n",
    "#     print(f\"F1 score: {f1}\")\n",
    "#     print(f\"Confusion matrix:\\n{cm}\")\n",
    "\n",
    "#     # check if current classifier is the best one\n",
    "#     if f1 > best_f1_score:\n",
    "#         best_f1_score = f1\n",
    "#         best_classifier = name\n",
    "#         # save the best model\n",
    "#         joblib.dump(clf, best_classifier + '_model.pkl')\n",
    "        \n",
    "# print(f\"\\nBest classifier: {best_classifier} (F1 score: {best_f1_score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GaussianNB from version 0.24.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GridSearchCV from version 0.24.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GaussianNB' object has no attribute 'var_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m clf \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mgnb_model.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Make predictions on the test data\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Save the predictions to a file\u001b[39;00m\n\u001b[1;32m     11\u001b[0m product_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_json(file_path)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:499\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \n\u001b[1;32m    483\u001b[0m \u001b[39mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[39m    the best found parameters.\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    498\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 499\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_estimator_\u001b[39m.\u001b[39;49mpredict(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/naive_bayes.py:106\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    104\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    105\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X(X)\n\u001b[0;32m--> 106\u001b[0m jll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_joint_log_likelihood(X)\n\u001b[1;32m    107\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_[np\u001b[39m.\u001b[39margmax(jll, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/naive_bayes.py:515\u001b[0m, in \u001b[0;36mGaussianNB._joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(np\u001b[39m.\u001b[39msize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_)):\n\u001b[1;32m    514\u001b[0m     jointi \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_prior_[i])\n\u001b[0;32m--> 515\u001b[0m     n_ij \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mlog(\u001b[39m2.0\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mpi \u001b[39m*\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvar_[i, :]))\n\u001b[1;32m    516\u001b[0m     n_ij \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msum(((X \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtheta_[i, :]) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m) \u001b[39m/\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvar_[i, :]), \u001b[39m1\u001b[39m)\n\u001b[1;32m    517\u001b[0m     joint_log_likelihood\u001b[39m.\u001b[39mappend(jointi \u001b[39m+\u001b[39m n_ij)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GaussianNB' object has no attribute 'var_'"
     ]
    }
   ],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# import joblib\n",
    "\n",
    "# # Load the saved model from a file\n",
    "# clf = joblib.load('gnb_model.pkl')\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# # Save the predictions to a file\n",
    "# product_test = pd.read_json(file_path)\n",
    "# product_test['predicted_class'] = y_pred\n",
    "# product_test.to_json(\"predictions.json\", orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Decision Tree:\n",
      "Best parameters: {'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Accuracy: 0.5510125974649386\n",
      "Precision: 0.5498923496483422\n",
      "Recall: 0.9218349595158748\n",
      "F1 score: 0.6888640153916004\n",
      "Confusion matrix:\n",
      "[[ 8321 62718]\n",
      " [ 6497 76622]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dt_model.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define hyperparameters for decision tree classifier\n",
    "# dt_params = {\n",
    "#     'max_depth': [2, 3, 4, 5],\n",
    "#     'min_samples_leaf': [1, 2, 3],\n",
    "#     'min_samples_split': [2, 3, 4]\n",
    "# }\n",
    "\n",
    "# # fit decision tree classifier and make predictions on test set\n",
    "# clf = GridSearchCV(DecisionTreeClassifier(), dt_params, scoring='f1', cv=5)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# # compute evaluation metrics\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# precision = precision_score(y_test, y_pred)\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# # print results\n",
    "# print(\"Results for Decision Tree:\")\n",
    "# print(f\"Best parameters: {clf.best_params_}\")\n",
    "# print(f\"Accuracy: {accuracy}\")\n",
    "# print(f\"Precision: {precision}\")\n",
    "# print(f\"Recall: {recall}\")\n",
    "# print(f\"F1 score: {f1}\")\n",
    "# print(f\"Confusion matrix:\\n{cm}\")\n",
    "\n",
    "# # save the best model\n",
    "# joblib.dump(clf, 'dt_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Define hyperparameters for random forest classifier\n",
    "# rf_params = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [5, 10, 20],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'max_features': ['sqrt', 'log2']\n",
    "# }\n",
    "\n",
    "# # fit random forest classifier and make predictions on test set\n",
    "# clf = GridSearchCV(RandomForestClassifier(), rf_params, scoring='f1', cv=5)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# # compute evaluation metrics\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# precision = precision_score(y_test, y_pred)\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# # print results\n",
    "# print(\"Results for Random Forest Classifier:\")\n",
    "# print(f\"Best parameters: {clf.best_params_}\")\n",
    "# print(f\"Accuracy: {accuracy}\")\n",
    "# print(f\"Precision: {precision}\")\n",
    "# print(f\"Recall: {recall}\")\n",
    "# print(f\"F1 score: {f1}\")\n",
    "# print(f\"Confusion matrix:\\n{cm}\")\n",
    "\n",
    "# # save the best model\n",
    "# joblib.dump(clf, 'rf_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# # Define hyperparameters for gradient boosting classifier\n",
    "# gb_params = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [5, 10, 20],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'max_features': ['sqrt', 'log2']\n",
    "# }\n",
    "\n",
    "# # fit gradient boosting classifier and make predictions on test set\n",
    "# clf = GridSearchCV(GradientBoostingClassifier(), gb_params, scoring='f1', cv=5)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# # compute evaluation metrics\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# precision = precision_score(y_test, y_pred)\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# # print results\n",
    "# print(\"Results for Gradient Boosting Classifier:\")\n",
    "# print(f\"Best parameters: {clf.best_params_}\")\n",
    "# print(f\"Accuracy: {accuracy}\")\n",
    "# print(f\"Precision: {precision}\")\n",
    "# print(f\"Recall: {recall}\")\n",
    "# print(f\"F1 score: {f1}\")\n",
    "# print(f\"Confusion matrix:\\n{cm}\")\n",
    "\n",
    "# # save the best model\n",
    "# joblib.dump(clf, 'gb_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
