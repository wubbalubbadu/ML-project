{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d936b5",
   "metadata": {},
   "source": [
    "## Get to know the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86217f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mJupyter server crashed. Unable to connect. \n",
      "\u001b[1;31mError code from Jupyter: 1\n",
      "\u001b[1;31musage: jupyter.py [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "\u001b[1;31m                  [--paths] [--json] [--debug]\n",
      "\u001b[1;31m                  [subcommand]\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mJupyter: Interactive Computing\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mpositional arguments:\n",
      "\u001b[1;31m  subcommand     the subcommand to launch\n",
      "\u001b[1;31m\n",
      "\u001b[1;31moptions:\n",
      "\u001b[1;31m  -h, --help     show this help message and exit\n",
      "\u001b[1;31m  --version      show the versions of core jupyter packages and exit\n",
      "\u001b[1;31m  --config-dir   show Jupyter config dir\n",
      "\u001b[1;31m  --data-dir     show Jupyter data dir\n",
      "\u001b[1;31m  --runtime-dir  show Jupyter runtime dir\n",
      "\u001b[1;31m  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "\u001b[1;31m                 format.\n",
      "\u001b[1;31m  --json         output paths as machine-readable json\n",
      "\u001b[1;31m  --debug        output debug information about paths\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mAvailable subcommands:\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mJupyter command `jupyter-notebook` not found. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_dir = 'devided_dataset_v2'\n",
    "categories = ['CDs_and_Vinyl', 'Grocery_and_Gourmet_Food', 'Toys_and_Games']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "file_path = os.path.join(data_dir, categories[0], 'train', 'product_training.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def7480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "c0_product_train = pd.read_json(file_path)\n",
    "c0_product_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(data_dir, categories[0], 'train', 'review_training.json')\n",
    "c0_review_train = pd.read_json(file_path)\n",
    "c0_review_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7301d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c0_review_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3964fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c0_review_train.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19473d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c0_review_train.iloc[3].reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc2a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "c0_product_test1 = pd.read_json(os.path.join(data_dir, categories[0], 'test1', 'product_test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe6bbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c0_product_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a95b1a",
   "metadata": {},
   "source": [
    "## Merge review and product data into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eb3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "c0_train = c0_review_train.merge(c0_product_train, how='left', on='asin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bcb3ae",
   "metadata": {},
   "source": [
    "## Use sklearn's train_test_split to split into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f6c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(c0_train, test_size=0.15, random_state=888)\n",
    "X_train = train.drop(['asin', 'awesomeness'], axis=1)\n",
    "Y_train = train['awesomeness']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714c78d4",
   "metadata": {},
   "source": [
    "## Clean up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9801bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some reviewText are missing, convert them to empty string\n",
    "\n",
    "X_train['reviewText'] = X_train['reviewText'].fillna('')\n",
    "X_train['summary'] = X_train['summary'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81612a23",
   "metadata": {},
   "source": [
    "## Convert reviewText and summary into vectors\n",
    "reviewText and summary are text, they can not be used directly in calculation, they must be converted into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6225540",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "c_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# this will take a long time\n",
    "reviewText_matrix = c_vectorizer.fit_transform(X_train['reviewText'])\n",
    "\n",
    "##########################################\n",
    "# This does not work because it use too many memory\n",
    "#   reported it needed 1.5 TB of ram\n",
    "###########################################\n",
    "# reviewText_matrix = reviewText_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4788ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewText_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35767694",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = c_vectorizer.get_feature_names_out()\n",
    "len(ft)\n",
    "# we got 309935\n",
    "# this is too many, switch to HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f56844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "h_vectorizer = HashingVectorizer(n_features=30000)\n",
    "\n",
    "# Fit the vectorizer to the text data and transform the data, will take 30s to 2min\n",
    "reviewText_matrix = h_vectorizer.fit_transform(X_train['reviewText'])\n",
    "reviewText_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486519af",
   "metadata": {},
   "source": [
    "## ~~convert sparse matrix to array~~\n",
    "this does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a4ed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this require 146 GB of memory\n",
    "#reviewText_dense = reviewText_matrix.toarray()\n",
    "\n",
    "# this still give memoryerror\n",
    "## Define a generator expression to iterate over the rows of the sparse matrix\n",
    "# def row_generator(X):\n",
    "#    for i in range(X.shape[0]):\n",
    "#        yield X[i,:].toarray()\n",
    "        \n",
    "## Use the generator expression to convert the sparse matrix to a list of dense numpy arrays\n",
    "#reviewText_list = list(row_generator(reviewText_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831ff277",
   "metadata": {},
   "source": [
    "## convert to pandas sparse dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8721b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviewText = pd.DataFrame.sparse.from_spmatrix(reviewText_matrix,\n",
    "                                                  columns=[f'r_{i}' for i in range(reviewText_matrix.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea79f14f",
   "metadata": {},
   "source": [
    "## Do the same for summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c8564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary has less text so use less features\n",
    "h_vectorizer = HashingVectorizer(n_features=5000)\n",
    "\n",
    "# Fit the vectorizer to the text data and transform the data, will take 30s to 2min\n",
    "summary_matrix = h_vectorizer.fit_transform(X_train['summary'])\n",
    "df_summary = pd.DataFrame.sparse.from_spmatrix(summary_matrix,\n",
    "                                               columns=[f's_{i}' for i in range(summary_matrix.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa34f0e1",
   "metadata": {},
   "source": [
    "## Combine 2 sparse dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd51d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "df_combined = sparse.hstack([df_reviewText, df_summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e003b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviewText_dense = df_reviewText.sparse.to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7f16c",
   "metadata": {},
   "source": [
    "## put them back to X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8665da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This doesn't work because concat remove sparseness so it's very slow\n",
    "X_train = X_train.drop(columns=['reviewText', 'summary'])\n",
    "X_train = pd.concat([X_train, df_reviewText, df_summary], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb2fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67af7a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewText_df = pd.DataFrame.sparse.from_spmatrix(reviewText_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad128b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewText_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6d058c",
   "metadata": {},
   "source": [
    "## convert to dense matrix with limited memory\n",
    "We can not do it in one go, have to do it in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a8fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "reviewText_dense_matrix = np.empty((reviewText_matrix.shape[0], vectorizer.vocabulary_.size), dtype=np.int)\n",
    "for i in range(reviewText_matrix.shape[0], batch_size):\n",
    "    reviewText_dense_matrix[i:i+batch_size] = reviewText_matrix[i:i+batch_size].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b79ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewText_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36210db3",
   "metadata": {},
   "source": [
    "## Train the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg_model = LinearRegression().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eb54ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
